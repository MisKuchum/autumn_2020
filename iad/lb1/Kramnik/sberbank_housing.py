# -*- coding: utf-8 -*-
"""Sberbank_housing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SYDsGfPnIn_91EUMy32_N3kAg_iaPOJn

Установка Keras Tuner
"""

!pip install -U keras-tuner

"""Импорт модулей"""

import keras
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
from sklearn import preprocessing
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import Callback
from kerastuner.tuners import Hyperband
import IPython

"""Загрузка данных"""

data = pd.read_csv('/content/drive/My Drive/data_analystic/lab1/train.csv')
data.head()

"""# Подготовка данных

Удаление столбцов  id и timestamp
"""

del data['id']
del data['timestamp']
data.head()

"""Сохранение значений таргетного поля"""

y = data.get('price_doc')
data = data.drop('price_doc', axis=1)
y

"""Замена полей, содержащих NaN или текстовые значения"""

data[data.columns] = SimpleImputer(strategy="most_frequent").fit_transform(data[data.columns])
df = pd.DataFrame(data)
data = df.apply(preprocessing.LabelEncoder().fit_transform)
data.head()

"""Стандартизация данных"""

mean = data.mean(axis=0)
std = data.std(axis=0)
data -= mean
data /= std
data.head()

"""# Создание и обучение нейросети"""

x_train, x_test, y_train, y_test = train_test_split(data, y, test_size=0.3, random_state = 2)

"""Создание и обучение нейросети"""

model = Sequential()
model.add(Dense(512, activation="relu", input_shape=(x_train.shape[1],)))
model.add(Dropout(0.2))
model.add(Dense(248, activation="relu"))
model.add(Dense(122, activation="relu"))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mse', metrics=['mae'])
 
model.summary()

history = model.fit(x_train, y_train, epochs=50, batch_size=125, verbose=2, validation_split=0.3)
print(history)
history = history.history
print("[INFO] Training has been finished")

"""Построение графика"""

def graphs(history):
    loss = history["loss"]
    val_loss = history["val_loss"]
    epochs = range(1, len(history['loss']) + 1)
    plt.plot(epochs, loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()
 
    plt.clf()
 
    mae = history['mae']
    val_mae = history['val_mae']
    plt.plot(epochs, mae, 'r', label='Training mae')
    plt.plot(epochs, val_mae, 'b', label='Validation mae')
    plt.title('Training and validation mae')
    plt.xlabel('Epochs')
    plt.ylabel('mae')
    plt.legend()
    plt.show()

graphs(history)

"""Предсказания и подсчет коэффициента корреляции"""

predicted_y = model.predict(x_test)
predicted_y = np.reshape(predicted_y, (predicted_y.shape[0]))

cc = np.corrcoef(predicted_y, y_test)
cc = cc[0][1]
print(f'Correlation Coefficient: {cc}')

"""# Keras Tuner

Создание модели
"""

def build_model(hp):
  hidden_layers = hp.Choice('hidden_layers', values=[1,2,3])
  activation_choice = hp.Choice('activation', values=['relu', 'selu', 'elu'])
  model = Sequential()
  model.add(Dense(units=hp.Int('units',min_value=256,max_value=512,step=32),activation=activation_choice, input_shape=(x_train.shape[1], )))
  model.add(Dropout(0.3))
  for i in range(hidden_layers):
    model.add(Dense(units=hp.Int(f'layer_{i}_units_',min_value=32//(i+1), max_value=128//(i+1),step=64//(i+1)),activation=activation_choice))
  model.add(Dense(1))  
  model.compile(optimizer='rmsprop', loss="mse", metrics=["mae"])
  return model

"""Поиск лучшей модели с помощью Hyperband"""

def find_best(x_train, y_train):
  # создаю тюнер, который сможет подобрать оптимальную архитектуру модели
  tuner = Hyperband(build_model, objective="loss", max_epochs=10, hyperband_iterations=3)
  print("\n\n\n")
  # начинается автоматический подбор гиперпараметров
  print('[INFO] start searching')
  tuner.search(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2)
  # выбираем лучшую модель
  print("\n\n\nRESULTS SUMMARY")
  tuner.results_summary()
  print("\n\n\n")
  # получаем лучшую модель
  print("\n\n\nHERE IS THE BEST MODEL\n\n\n")
  best_params = tuner.get_best_hyperparameters()[0]
  best_model = tuner.hypermodel.build(best_params)
  best_model.summary()
  return best_model
  

best_model = find_best(x_train, y_train)

"""Обучение лучшей модели"""

best_history = best_model.fit(x_train, y_train, epochs=50, batch_size=125, validation_split=0.3)
best_history = best_history.history
print("[INFO] Training has been finished")

"""Построение графиков лучшей модели"""

graphs(best_history)

"""Предсказания и подсчет коэффициента корреляции лучшей модели"""

best_predicted_y = best_model.predict(x_test)
best_predicted_y = np.reshape(best_predicted_y, (best_predicted_y.shape[0]))

best_cc = np.corrcoef(best_predicted_y, y_test)
best_cc = best_cc[0][1]
print(f'Correlation Coefficient: {best_cc}')